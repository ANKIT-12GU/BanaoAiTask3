{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a0721d-111b-487c-ba09-309a807db233",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fefc89-e1cb-49a9-8245-13b3c282c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pyautogui\n",
    "import pytesseract\n",
    "import psutil\n",
    "import pygetwindow as gw\n",
    "import webbrowser\n",
    "from transformers import pipeline\n",
    "from plyer import notification\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d273d-7790-4a5b-abef-89fef26ebfbf",
   "metadata": {},
   "source": [
    "## Set correct Tesseract path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d150c71-8d93-4fab-ab8b-4d1877a3cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce799da-2632-40ee-aaf3-e1c5ef01a54a",
   "metadata": {},
   "source": [
    "# Load LLM Model (Using small open-source model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833182ee-b48f-4f72-b926-5191b9301271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "llm = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83213c-7e21-495f-9516-d808cb8c085e",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ec8b32-8334-4e00-86fb-24ddb3f8798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTURE_INTERVAL = 2  # Reduced interval for quicker tab detection\n",
    "LOG_FILE = \"logs.json\"\n",
    "EXPECTED_ACTIVITIES = \"expected_activities.json\"\n",
    "PREVIOUS_TAB = None\n",
    "CONFIDENCE_THRESHOLD = 0.75  # Minimum confidence level for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34134557-ebe7-4f97-a1f3-56304921e763",
   "metadata": {},
   "source": [
    "# Collect user input for intended activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c405bf-5636-43b2-8a53-8f01862c22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_intended_activities():\n",
    "    user_input = input(\"Describe your planned activities (e.g., 'I will be coding in VSCode and researching Python on GFG'): \")\n",
    "    \n",
    "    work_related_keywords = [\"programming\", \"Github\", \"Hackerrank\", \"GFG\", \"Jupyter Notebook\", \"Terminal\"]\n",
    "    not_work_related_keywords = [\"Netflix\", \"YouTube\", \"Hotstar\", \"movies\", \"entertainment\", \"social media\"]\n",
    "    \n",
    "    extracted_activities = {\n",
    "        \"work-related\": [word for word in work_related_keywords if word.lower() in user_input.lower()],\n",
    "        \"not work-related\": [word for word in not_work_related_keywords if word.lower() in user_input.lower()]\n",
    "    }\n",
    "    \n",
    "    with open(EXPECTED_ACTIVITIES, 'w') as f:\n",
    "        json.dump(extracted_activities, f, indent=4)\n",
    "    print(f\"Stored intended activities: {extracted_activities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccc13a-4d3b-4491-a714-5d190091be23",
   "metadata": {},
   "source": [
    "# Load expected activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb65db97-0456-41fe-8b1b-2e2a3532a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expected_activities():\n",
    "    if os.path.exists(EXPECTED_ACTIVITIES):\n",
    "        with open(EXPECTED_ACTIVITIES, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978bb1f-c892-4a72-97ee-a0219f1cd67f",
   "metadata": {},
   "source": [
    "# Take screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25109458-3ea8-4e95-b136-061769133aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_screen():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"screenshots/{timestamp}.png\"\n",
    "    os.makedirs(\"screenshots\", exist_ok=True)\n",
    "    pyautogui.screenshot(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d093f-0063-43a4-94c1-f8ae9d2a59f1",
   "metadata": {},
   "source": [
    "# Extract text using OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b75a7b6-756d-49e2-8f81-6b5d962ef65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image_path):\n",
    "    text = pytesseract.image_to_string(image_path)\n",
    "    text = text.strip().lower()\n",
    "    print(f\"DEBUG: Extracted Text: {text}\")  # Debugging output\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a077a1-4860-40d8-9ec4-dc0e1fde84fc",
   "metadata": {},
   "source": [
    "# Get active browser tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7b52cc4-cfd0-41a1-a774-c4e307433cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_browser_tab():\n",
    "    for window in gw.getWindowsWithTitle(\" \"):\n",
    "        if \"Google Chrome\" in window.title or \"Mozilla Firefox\" in window.title or \"Edge\" in window.title:\n",
    "            return window.title\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43598a36-13b7-4bd6-a050-52f5d5ec112e",
   "metadata": {},
   "source": [
    "# Analyze content with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d0da6ca-0c12-4d1e-add2-15dd1e41f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_content(text, expected_activities):\n",
    "    if not text.strip():\n",
    "        return \"unknown\"\n",
    "    try:\n",
    "        work_keywords = expected_activities.get(\"work-related\", [])\n",
    "        not_work_keywords = expected_activities.get(\"not work-related\", [])\n",
    "\n",
    "        # Ensure strict keyword matching for classification\n",
    "        detected_category = \"not work-related\"  # Default assumption\n",
    "        for keyword in work_keywords:\n",
    "            if keyword.lower() in text:\n",
    "                detected_category = \"work-related\"\n",
    "                break\n",
    "        for keyword in not_work_keywords:\n",
    "            if keyword.lower() in text:\n",
    "                detected_category = \"not work-related\"\n",
    "                break\n",
    "        \n",
    "        # Use LLM classification only if no keywords matched\n",
    "        if detected_category == \"not work-related\":\n",
    "            result = llm(text, candidate_labels=[\"work-related\", \"not work-related\"], return_all_scores=True)\n",
    "            print(f\"DEBUG: LLM Classification Output: {result}\")  # Debugging output\n",
    "            \n",
    "            if result and isinstance(result, list) and \"scores\" in result[0]:\n",
    "                scores = {entry.get(\"label\", \"unknown\"): entry.get(\"score\", 0) for entry in result[0]}\n",
    "                if scores.get(\"work-related\", 0) > CONFIDENCE_THRESHOLD:\n",
    "                    detected_category = \"work-related\"\n",
    "        \n",
    "        return detected_category\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: LLM Classification Failed - {str(e)}\")\n",
    "        return \"not work-related\"\n",
    "    if not text.strip():\n",
    "        return \"unknown\"\n",
    "    try:\n",
    "        work_keywords = expected_activities.get(\"work-related\", [])\n",
    "        not_work_keywords = expected_activities.get(\"not work-related\", [])\n",
    "\n",
    "        if any(keyword.lower() in text for keyword in work_keywords):\n",
    "            return \"work-related\"\n",
    "        elif any(keyword.lower() in text for keyword in not_work_keywords):\n",
    "            return \"not work-related\"\n",
    "        \n",
    "        result = llm(text, candidate_labels=[\"work-related\", \"not work-related\"], return_all_scores=True)\n",
    "        print(f\"DEBUG: LLM Classification Output: {result}\")  # Debugging output\n",
    "        \n",
    "        if not result or \"scores\" not in result[0]:\n",
    "            return \"not work-related\"\n",
    "        \n",
    "        scores = {entry.get(\"label\", \"unknown\"): entry.get(\"score\", 0) for entry in result[0]}\n",
    "        detected_category = \"not work-related\"\n",
    "        \n",
    "        if scores.get(\"work-related\", 0) > CONFIDENCE_THRESHOLD:\n",
    "            detected_category = \"work-related\"\n",
    "        \n",
    "        return detected_category\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: LLM Classification Failed - {str(e)}\")\n",
    "        return \"not work-related\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e418f-0ff8-42e4-9c72-670a5dce8b7d",
   "metadata": {},
   "source": [
    "# Privacy and security: Delete logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ca691f4-2461-417f-a044-ac54b3066ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_logs():\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        os.remove(LOG_FILE)\n",
    "        print(\"Logs deleted successfully.\")\n",
    "    else:\n",
    "        print(\"No logs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104b37b-7a9c-4863-a7a0-19f226452f96",
   "metadata": {},
   "source": [
    "# Generate productivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c2a657d-caf7-4577-bb72-030cccd19bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate productivity analysis\n",
    "def analyze_logs():\n",
    "    if not os.path.exists(LOG_FILE):\n",
    "        print(\"No log data available.\")\n",
    "        return\n",
    "    with open(LOG_FILE, 'r') as f:\n",
    "        logs = json.load(f)\n",
    "    work_count = sum(1 for entry in logs if entry[\"category\"] == \"work-related\")\n",
    "    non_work_count = sum(1 for entry in logs if entry[\"category\"] == \"not work-related\")\n",
    "    labels = [\"Work\", \"Distractions\"]\n",
    "    counts = [work_count, non_work_count]\n",
    "    plt.bar(labels, counts)\n",
    "    plt.title(\"Productivity Analysis\")\n",
    "    plt.ylabel(\"Activity Count\")\n",
    "    plt.savefig('productivity_analysis.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f7c177-ad4f-49b1-a4a3-33a01ba2ebb6",
   "metadata": {},
   "source": [
    "# Send notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c02d8d13-819c-4a28-8d9e-7c3b0c68d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_notification(category):\n",
    "    if category == \"work-related\":\n",
    "        return  # Do not send notification for work-related activities\n",
    "    \n",
    "    messages = {\n",
    "        \"work-related\": \"You are on track! Keep up the great work!\",\n",
    "        \"not work-related\": \"Refocus on your tasks to stay productive.\"\n",
    "    }\n",
    "    message = messages.get(category, f\"Detected category: {category}\")\n",
    "    print(f\"DEBUG: Sending Notification: {message}\")  # Debugging output\n",
    "    try:\n",
    "        notification.notify(\n",
    "            title=\"Attention!\",\n",
    "            message=message,\n",
    "            timeout=5\n",
    "        )\n",
    "        print(\"DEBUG: Notification sent successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Notification failed! {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1642a-4883-4fa8-be45-e0ccd425259f",
   "metadata": {},
   "source": [
    "# Log activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "181dca84-4976-497b-9cb9-54eea2f4f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_activity(activity):\n",
    "    logs = []\n",
    "    if os.path.exists(LOG_FILE):\n",
    "        with open(LOG_FILE, 'r') as f:\n",
    "            logs = json.load(f)\n",
    "    logs.append(activity)\n",
    "    with open(LOG_FILE, 'w') as f:\n",
    "        json.dump(logs, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0614b-9111-4d81-93c1-c6b64a1c53d2",
   "metadata": {},
   "source": [
    "# Main monitoring loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1dd1de1-6183-44b1-857a-98b2e66dc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor():\n",
    "    global PREVIOUS_TAB\n",
    "    get_user_intended_activities()\n",
    "    expected_activities = load_expected_activities()\n",
    "    while True:\n",
    "        current_tab = get_active_browser_tab()\n",
    "        print(f\"DEBUG: Active Tab: {current_tab}\")\n",
    "        screenshot_path = capture_screen()\n",
    "        extracted_text = extract_text(screenshot_path)\n",
    "        detected_category = analyze_content(extracted_text, expected_activities)\n",
    "        log_activity({\"timestamp\": str(datetime.now()), \"browser_tab\": current_tab, \"content\": extracted_text, \"category\": detected_category})\n",
    "        if detected_category == \"not work-related\":\n",
    "            send_notification(detected_category)\n",
    "        PREVIOUS_TAB = current_tab\n",
    "        time.sleep(CAPTURE_INTERVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8decc-cfcd-4c5a-a369-905d6b481885",
   "metadata": {},
   "source": [
    "# Main Function Called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd502481-4b17-4750-a309-b29747ccc935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Describe your planned activities (e.g., 'I will be coding in VSCode and researching Python on GFG'):  i am working with jupyter notebook, gfg, github for work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored intended activities: {'work-related': ['Github', 'GFG', 'Jupyter Notebook'], 'not work-related': []}\n",
      "DEBUG: Active Tab: Procrastination Preventer - Google Chrome\n",
      "DEBUG: Extracted Text: procrastinati: x b 2) youtube netflix ind\n",
      "\n",
      "<= jupyter procrastination preventer last checkpoint: 51 seconds ago 2\n",
      "file edit view run kemel settings help trusted\n",
      "@+ xx 0 o > = cg » code v jupyterlab (7 python [conda env:base]* ©) =\n",
      "\n",
      "v v x\n",
      "\n",
      "def monitor():\n",
      "global previous_tab\n",
      "get_user_intended_activities()\n",
      "expected_activities = load_expected_activities()\n",
      "while true:\n",
      "current_tab = get_active_browser_tab()\n",
      "print(f\"debug: active tab: {current_tab}\")\n",
      "screenshot_path = capture_screen()\n",
      "extracted_text = extract_text(screenshot_path)\n",
      "detected_category = analyze_content(extracted_text, expected_activities)\n",
      "\n",
      "str(datetime.now()), “browser_tab\": current_tab, \"content\": extracted_text, \"category\": detected_category})\n",
      "\n",
      "log_activity({\"timestam\n",
      "\n",
      "if detected_category == “not work-related\":\n",
      "send_notification(detected_category)\n",
      "previous_tab = current_tab\n",
      "\n",
      "time. sleep(capture_interval)\n",
      "\n",
      "main function called\n",
      "\n",
      "[*]: af _name_ main\": +e nn 47 58\n",
      "monitor()\n",
      "describe your planned activities (e.g., ‘i will be coding in vscode and researching python on gfg'):\n",
      "iam working with jupyter notebook, gfg, github for work] a\n",
      "\n",
      "01:30\n",
      "\n",
      "q search a 09-02-2025\n",
      "DEBUG: Active Tab: Procrastination Preventer - Google Chrome\n",
      "DEBUG: Extracted Text: procrastinat' c g (2) your x d > iment\n",
      "\n",
      "<= jupyter procrastination preventer last checkpoint: 55 seconds ago 2\n",
      "file edit view run kernel settings help trusted\n",
      "@+ xx © f > & gc » code v jupyterlab (2 python [conda env:base]* ©) =\n",
      "\n",
      "global previous_tab\n",
      "get_user_intended_activities()\n",
      "expected_activities = load_expected_activities()\n",
      "while true:\n",
      "current_tab = get_active_browser_tab()\n",
      "print(f\"debug: active tab: {current_tab}\"\n",
      "screenshot_path = capture_screen()\n",
      "\n",
      "extracted_text = extract_text(screenshot_path)\n",
      "detected_category = analyze_content(extracted_text, expected_activities)\n",
      "str(datetime.now()), \"browser_tal\n",
      "\n",
      "detected_category})\n",
      "\n",
      "log_activity({\"timestamp\" current_tab, \"content\": extracted_text, \"category\n",
      "\n",
      "if detected_category == “not work-related\":\n",
      "send_notification(detected_category)\n",
      "previous_tab = current_tab\n",
      "\n",
      "time. sleep(capture_interval)\n",
      "\n",
      "main function called\n",
      "\n",
      "+ ot 4 f\n",
      "\n",
      "[*]: af _name__\n",
      "\n",
      "_main_\":\n",
      "\n",
      "monitor()\n",
      "\n",
      "str(datetime.now()), “browser_tab\": current_tab, \"content\": extracted_text, \"category\": detected_category})\n",
      "\n",
      "log_activity({\"timestam\n",
      "\n",
      "if detected_category == “not work-related\":\n",
      "send_notification(detected_category)\n",
      "previous_tab = current_tab\n",
      "\n",
      "time. sleep(capture_interval)\n",
      "\n",
      "main function called\n",
      "\n",
      "[*]: af _name_ main\": +e nn 47 58 .\n",
      "\n",
      "01:30\n",
      "\n",
      "q search 09-02-2025\n",
      "DEBUG: LLM Classification Output: {'sequence': 'procrastinat\\' c g (2) your x d > iment\\n\\n<= jupyter procrastination preventer last checkpoint: 55 seconds ago 2\\nfile edit view run kernel settings help trusted\\n@+ xx © f > & gc » code v jupyterlab (2 python [conda env:base]* ©) =\\n\\nglobal previous_tab\\nget_user_intended_activities()\\nexpected_activities = load_expected_activities()\\nwhile true:\\ncurrent_tab = get_active_browser_tab()\\nprint(f\"debug: active tab: {current_tab}\"\\nscreenshot_path = capture_screen()\\n\\nextracted_text = extract_text(screenshot_path)\\ndetected_category = analyze_content(extracted_text, expected_activities)\\nstr(datetime.now()), \"browser_tal\\n\\ndetected_category})\\n\\nlog_activity({\"timestamp\" current_tab, \"content\": extracted_text, \"category\\n\\nif detected_category == “not work-related\":\\nsend_notification(detected_category)\\nprevious_tab = current_tab\\n\\ntime. sleep(capture_interval)\\n\\nmain function called\\n\\n+ ot 4 f\\n\\n[*]: af _name__\\n\\n_main_\":\\n\\nmonitor()\\n\\nstr(datetime.now()), “browser_tab\": current_tab, \"content\": extracted_text, \"category\": detected_category})\\n\\nlog_activity({\"timestam\\n\\nif detected_category == “not work-related\":\\nsend_notification(detected_category)\\nprevious_tab = current_tab\\n\\ntime. sleep(capture_interval)\\n\\nmain function called\\n\\n[*]: af _name_ main\": +e nn 47 58 .\\n\\n01:30\\n\\nq search 09-02-2025', 'labels': ['work-related', 'not work-related'], 'scores': [0.648036539554596, 0.35196346044540405]}\n",
      "DEBUG: Sending Notification: Refocus on your tasks to stay productive.\n",
      "DEBUG: Notification sent successfully.\n",
      "DEBUG: Active Tab: GitHub · Build and ship software on a single, collaborative platform · GitHub - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | jk procrastinatii x | 26 machinelea’ x €) github-buil’ x 9 (2)youtube x | \\ netflixindia. x | ah disney+hot x | © entailmentar x | @ task3:procre xx | + = a x\n",
      "€ > g (8% githubcom ge ©) @\n",
      "\n",
      "github copilot is now available for free. learn more x\n",
      "\n",
      "() product y solutions y resources ¥ opensource y enterprise y pricing search or jump to... / sign in | sign up ]\n",
      "\n",
      "build and ship software on a\n",
      "single, collaborative platform\n",
      "\n",
      "join the world’s most widely adopted al-powered developer platform.\n",
      "\n",
      "os sanaa\n",
      "\n",
      "@ python . x\n",
      "\n",
      "attention!\n",
      "refocus on your tasks to stay productive.\n",
      "\n",
      "76°f\n",
      "clear\n",
      "\n",
      "aaa set eaedhmma goo +6 % cee yam\n",
      "DEBUG: Active Tab: GitHub · Build and ship software on a single, collaborative platform · GitHub - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | jk procrastinatii x | 26 machinelea’ x €) github-buil’ x 9 (2)youtube x | \\ netflixindia. x | ah disney+hot x | © entailmentar x | @ task3:procre xx | + = a x\n",
      "€ > g (8% githubcom ge ©) @\n",
      "\n",
      "github copilot is now available for free. learn more x\n",
      "\n",
      "() product y solutions y resources ¥ opensource y enterprise y pricing search or jump to... / sign in | sign up ]\n",
      "\n",
      "build and ship software on a\n",
      "single, collaborative platform\n",
      "\n",
      "join the world’s most widely adopted al-powered developer platform.\n",
      "\n",
      "os sanaa\n",
      "\n",
      "@ python . x\n",
      "\n",
      "attention!\n",
      "refocus on your tasks to stay productive.\n",
      "\n",
      "air: very poor\n",
      "now\n",
      "\n",
      "aaa set eaedhmma goo +6 % cee yam\n",
      "DEBUG: Active Tab: GitHub · Build and ship software on a single, collaborative platform · GitHub - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xx procrastinatii x | 26 machinelea’ x €) github-buil x ©) (youtube %&% \\ netflixindia x | ah disney+hot xx | © entailmentar x | @ task3:procre xx | + = a x\n",
      "\n",
      "€ > g 8% github.com (2) youtube gre @©2)|@\n",
      "youtube.com\n",
      "\n",
      "ae |\n",
      "allel is search or jump to... /)| signin | signup |\n",
      "\n",
      "learn more x\n",
      "\n",
      "() product y solutions y resources y opensource v_ enterprise\n",
      "\n",
      "@ memory usage: 222 mb\n",
      "\n",
      "build and ship software on a\n",
      "single, collaborative platform\n",
      "\n",
      "join the world’s most widely adopted al-powered developer platform.\n",
      "\n",
      "ts seaneind\n",
      "\n",
      "+\n",
      "\n",
      "air: very poor\n",
      "now\n",
      "\n",
      "aac spr eeomma gos .6% coo ,.m\n",
      "DEBUG: Active Tab: Netflix India – Watch TV Shows Online, Watch Movies Online - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinatii x | 26 machinelear x | ©) github-buil x | @9 (2)youtube xx | netflixindia. x © 2h disney+hot x | © entailmentar x | @ task3:procre x | + = a\n",
      "\n",
      "€ > g  & netflixcomyin/ rr od @\n",
      "\n",
      "trending now\n",
      "\n",
      "relsaded version\n",
      "\n",
      "more reasons to join\n",
      "\n",
      "enjoy on your tv download your shows\n",
      "\n",
      "watch on smart tvs, playstation, to watch offline\n",
      "xbox, chromecast, apple tv, blu-ray\n",
      "\n",
      "watch everywhere create profiles for kids\n",
      "\n",
      "stream unlimited movies and tv send kids on adventures with their\n",
      "revetcuriaveuntesteaciivand shows on your phone, tablet, laptop favourite characters in a ageais made\n",
      "\n",
      "air: very poor\n",
      "\n",
      "sern q search seseeommago o@- acy © sey 01:31\n",
      "\n",
      "in 09-02-2025\n",
      "DEBUG: Active Tab: Netflix India – Watch TV Shows Online, Watch Movies Online - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinatii x | 26 machinelear x | ©) github-buil x | @9 (2)youtube xx | netflixindia. x © 2h disney+hot x | © entailmentar x | @ task3:procre x | + = a\n",
      "\n",
      "€ > g  & netflixcomyin/ rr od @\n",
      "\n",
      "trending now\n",
      "\n",
      "relsaded version\n",
      "\n",
      "more reasons to join\n",
      "\n",
      "enjoy on your tv download your shows\n",
      "\n",
      "watch on smart tvs, playstation, to watch offline\n",
      "xbox, chromecast, apple tv, blu-ray\n",
      "\n",
      "watch everywhere create profiles for kids\n",
      "\n",
      "stream unlimited movies and tv send kids on adventures with their\n",
      "revetcuriaveuntesteaciivand shows on your phone, tablet, laptop favourite characters in a ageais made\n",
      "\n",
      "air: very poor\n",
      "\n",
      "sern q search seseeommago o@- acy © sey 01:31\n",
      "\n",
      "in 09-02-2025\n",
      "DEBUG: Active Tab: Netflix India – Watch TV Shows Online, Watch Movies Online - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinatii x | 26 machinelear x | ©) github-buil x | @9 (2)youtube xx | netflixindia. x © 2h disney+hot x | © entailmentar x | @ task3:procre x | + = a\n",
      "\n",
      "€ > g  & netflixcomyin/ rr od @\n",
      "\n",
      "trending now\n",
      "\n",
      "relsaded version\n",
      "\n",
      "more reasons to join\n",
      "\n",
      "enjoy on your tv download your shows\n",
      "\n",
      "watch on smart tvs, playstation, to watch offline\n",
      "xbox, chromecast, apple tv, blu-ray\n",
      "\n",
      "watch everywhere create profiles for kids\n",
      "\n",
      "stream unlimited movies and tv send kids on adventures with their\n",
      "revetcuriaveuntesteaciivand shows on your phone, tablet, laptop favourite characters in a ageais made\n",
      "\n",
      "air: very poor\n",
      "\n",
      "sern q search seseeommago o@- ao 8 aaw 01:31\n",
      "\n",
      "in 09-02-2025\n",
      "DEBUG: Active Tab: Netflix India – Watch TV Shows Online, Watch Movies Online - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinatii x | 26 machinelear x | ©) github-buil x | @9 (2)youtube xx | netflixindia. x © 2h disney+hot x | © entailmentar x | @ task3:procre x | + = a\n",
      "\n",
      "€ > g  & netflixcomyin/ rr od @\n",
      "\n",
      "trending now\n",
      "\n",
      "relsaded version\n",
      "\n",
      "more reasons to join\n",
      "\n",
      "enjoy on your tv download your shows\n",
      "\n",
      "watch on smart tvs, playstation, to watch offline\n",
      "xbox, chromecast, apple tv, blu-ray\n",
      "\n",
      "watch everywhere create profiles for kids\n",
      "\n",
      "stream unlimited movies and tv send kids on adventures with their\n",
      "revetcuriaveuntesteaciivand shows on your phone, tablet, laptop favourite characters in a ageais made\n",
      "\n",
      "air: very poor\n",
      "\n",
      "sern q search seseeommago o@- ao 8 aaw 01:31\n",
      "\n",
      "in 09-02-2025\n",
      "DEBUG: Active Tab: Netflix India – Watch TV Shows Online, Watch Movies Online - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinatii x | 26 machinelear x | ©) github-buil x | @9 (2)youtube xx | netflixindia. x © 2h disney+hot x | © entailmentar x | @ task3:procre x | + = a\n",
      "\n",
      "€ > g  & netflixcomyin/ rr od @\n",
      "\n",
      "trending now\n",
      "\n",
      "relsaded version\n",
      "\n",
      "more reasons to join\n",
      "\n",
      "enjoy on your tv download your shows\n",
      "\n",
      "watch on smart tvs, playstation, to watch offline\n",
      "xbox, chromecast, apple tv, blu-ray\n",
      "\n",
      "watch everywhere create profiles for kids\n",
      "\n",
      "stream unlimited movies and tv send kids on adventures with their\n",
      "revetcuriaveuntesteaciivand shows on your phone, tablet, laptop favourite characters in a ageais made\n",
      "\n",
      "air: very poor\n",
      "\n",
      "sern q search seseeommago o@- ao 8 aaw 01:31\n",
      "\n",
      "in 09-02-2025\n",
      "DEBUG: Active Tab: Netflix India – Watch TV Shows Online, Watch Movies Online - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | jk procrastinatii x | 26 machinelear x | €) github-buil x | g9 (2)youtube x | netflixindia x | 2h disney+hot xx © entailmentar x | @ task3:procre x | + = a\n",
      "\n",
      "€ > g  & netflixcomyin/ rr od @\n",
      "\n",
      "trending now\n",
      "\n",
      "relsaded version\n",
      "\n",
      "more reasons to join\n",
      "\n",
      "enjoy on your tv download your shows\n",
      "\n",
      "watch on smart tvs, playstation, to watch offline\n",
      "xbox, chromecast, apple tv, blu-ray\n",
      "\n",
      "watch everywhere create profiles for kids\n",
      "\n",
      "stream unlimited movies and tv send kids on adventures with their\n",
      "revetcuriaveuntesteaciivand shows on your phone, tablet, laptop favourite characters in a ageais made\n",
      "\n",
      "air: very poor\n",
      "\n",
      "sern q search seseeommago o@- ao 8 aaw 01:31\n",
      "\n",
      "in 09-02-2025\n",
      "DEBUG: Active Tab: Disney+ Hotstar - Watch TV Shows, Movies, Specials, Live Cricket & Football - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinatii x | 26 machinelear x | ©) github-buil x | @® (2)youtube x | | netflixindia x | 2h disneyshot x © entailmentar x | @ task3:procre x | + = a x\n",
      "\n",
      "€ > g 8% hotstar.com/in/home?ref=92fin rr o01 a:\n",
      "dien) ~\n",
      "hotstar \\\n",
      "\n",
      "‘\n",
      "\n",
      "hotstar specials\n",
      "\n",
      "ra ke ‘\n",
      "usar ‘\n",
      "\n",
      "q envy\n",
      "2024's most watched show e\n",
      "k *\n",
      ") 2024 - u/a16+ + 1season - hindi ‘\n",
      "qr nae -\n",
      "“a two families clash over societal and caste dit 2\n",
      "so spurring a saga of revenge. all this happens,\n",
      "love story goes wrong. q\n",
      "se a .\n",
      "drama | betrayal | revenge | jon-man struggles\n",
      ",\n",
      "is hl ° .\n",
      "> ] a a lane\n",
      "oa) aan\n",
      "latest releases\n",
      "are = a eng 01:31\n",
      "nowe q search & e = e @o 1 | a s 1) 12) i l | ~ 2 ow pd© 6502-2005\n",
      "DEBUG: Active Tab: Disney+ Hotstar - Watch TV Shows, Movies, Specials, Live Cricket & Football - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinati x | 96 machinelea’ x | €) github-buil x | g9 (2)youtube x | | netflixindia xx | 2h disney+hot x © entailmenta’ x | @ task3:proc x + = a x\n",
      "\n",
      "€ > g 8% hotstar.com/in/home?ref=92fin er 00!1@\n",
      "\n",
      "love story goes wrong.\n",
      "\n",
      "ding\n",
      "hotstar drama | betrayal | revenge | common-man struggles\n",
      "b® watch now =f =} 2 lg\n",
      "a teal)\n",
      "aa\n",
      "\n",
      "latest releases\n",
      "\n",
      "the storyteller\n",
      "\n",
      "the\n",
      "storyteller\n",
      "\n",
      "af i\n",
      "ve secretor\n",
      "shiledars\n",
      "\n",
      "2025 + u/a7+ * 1h52m = hindi - drama\n",
      "\n",
      "a retiree takes up a job as a storyteller for an\n",
      "insomniac. what happens when he discovers\n",
      "that his tales are published under a pen name\n",
      "and have won accolades?\n",
      "\n",
      "pe\n",
      "\n",
      "01:31\n",
      "09-02-2025\n",
      "DEBUG: Active Tab: Disney+ Hotstar - Watch TV Shows, Movies, Specials, Live Cricket & Football - Google Chrome\n",
      "DEBUG: Extracted Text: vy home x | xk procrastinati x | 96 machinelea’ x | €) github-buil x | g9 (2)youtube x | | netflixindia xx | 2h disney+hot x © entailmenta’ x | @ task3:proc x + = a x\n",
      "\n",
      "€ > g 8% hotstar.com/in/home?ref=92fin er 00!1@\n",
      "\n",
      "love story goes wrong.\n",
      "\n",
      "diop\n",
      "\n",
      "hotstar drama | betrayal | revenge | common-man struggles\n",
      "» watch now ee\n",
      "\n",
      "aa\n",
      "\n",
      "latest releases\n",
      "\n",
      "cy i\n",
      "\n",
      "storyteller\n",
      "\n",
      "en\n",
      "hofstar speciais es > watch now +\n",
      "ye secre tor re\n",
      "\n",
      "shiledars\n",
      "\n",
      "2025 + u/a7+ +» 1h52m * hindi » drama\n",
      "\n",
      "aretiree takes up a job as a storyteller for an\n",
      "insomniac. what happens when he discovers\n",
      "that his tales are published under a pen name\n",
      "and have won accolades?\n",
      "\n",
      "01:31\n",
      "09-02-2025\n",
      "DEBUG: Active Tab: Procrastination Preventer - Google Chrome\n",
      "DEBUG: Extracted Text: procrastinat' c g (2) your x d > iment\n",
      "\n",
      "© jupyter procrastination preventer last checkpoint: 2 minutes ago &\n",
      "file edit view run kernel settings help trusted\n",
      "@+ xx 0 o > = cg » code v jupyterlab (7 python [conda env:base]* © =\n",
      "\n",
      "global previous_tab\n",
      "get_user_intended_activities()\n",
      "expected_activities = load_expected_activities()\n",
      "while true:\n",
      "current_tab = get_active_browser_tab()\n",
      "print(f\"debug: active tab: {current_tab}\"\n",
      "screenshot_path = capture_screen()\n",
      "\n",
      "extracted_text = extract_text(screenshot_path)\n",
      "detected_category = analyze_content(extracted_text, expected_activities)\n",
      "str(datetime.now()), \"browser_tal\n",
      "\n",
      "detected_category})\n",
      "\n",
      "log_activity({\"timestamp\" current_tab, \"content\": extracted_text, \"category\n",
      "\n",
      "if detected_category == “not work-related\":\n",
      "send_notification(detected_category)\n",
      "previous_tab = current_tab\n",
      "\n",
      "time. sleep(capture_interval)\n",
      "\n",
      "main function called\n",
      "\n",
      "+ ot 4 f\n",
      "\n",
      "[*]: af _name__\n",
      "\n",
      "_main_\":\n",
      "\n",
      "monitor()\n",
      "\n",
      "str(datetime.now()), “browser_tab\": current_tab, \"content\": extracted_text, \"category\": detected_category})\n",
      "\n",
      "log_activity({\"timestam\n",
      "\n",
      "if detected_category == “not work-related\":\n",
      "send_notification(detected_category)\n",
      "previous_tab = current_tab\n",
      "\n",
      "time. sleep(capture_interval)\n",
      "\n",
      "main function called\n",
      "\n",
      "[*]: af _name_ main\": +e nn 47 58 .\n",
      "\n",
      "o air very poor > 01:31\n",
      "\n",
      "now q search 09-02-2025\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     monitor()\n",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m, in \u001b[0;36mmonitor\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m screenshot_path \u001b[38;5;241m=\u001b[39m capture_screen()\n\u001b[0;32m      9\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m extract_text(screenshot_path)\n\u001b[1;32m---> 10\u001b[0m detected_category \u001b[38;5;241m=\u001b[39m analyze_content(extracted_text, expected_activities)\n\u001b[0;32m     11\u001b[0m log_activity({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow()), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowser_tab\u001b[39m\u001b[38;5;124m\"\u001b[39m: current_tab, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: extracted_text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m: detected_category})\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_category \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot work-related\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m, in \u001b[0;36manalyze_content\u001b[1;34m(text, expected_activities)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Use LLM classification only if no keywords matched\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_category \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot work-related\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 21\u001b[0m     result \u001b[38;5;241m=\u001b[39m llm(text, candidate_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork-related\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot work-related\u001b[39m\u001b[38;5;124m\"\u001b[39m], return_all_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: LLM Classification Output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging output\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[1;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(sequences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\base.py:1354\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1356\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1357\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1358\u001b[0m             )\n\u001b[0;32m   1359\u001b[0m         )\n\u001b[0;32m   1360\u001b[0m     )\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\base.py:1269\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1268\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1269\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1270\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    228\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[0;32m    231\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[0;32m    236\u001b[0m }\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1762\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1759\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1760\u001b[0m     )\n\u001b[1;32m-> 1762\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1763\u001b[0m     input_ids,\n\u001b[0;32m   1764\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1765\u001b[0m     decoder_input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m   1766\u001b[0m     decoder_attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[0;32m   1767\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1768\u001b[0m     decoder_head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[0;32m   1769\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[0;32m   1770\u001b[0m     encoder_outputs\u001b[38;5;241m=\u001b[39mencoder_outputs,\n\u001b[0;32m   1771\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1772\u001b[0m     decoder_inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[0;32m   1773\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1774\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1775\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1776\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1777\u001b[0m )\n\u001b[0;32m   1778\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1527\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1520\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1521\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1522\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1523\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1524\u001b[0m     )\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[0;32m   1528\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids,\n\u001b[0;32m   1529\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mdecoder_attention_mask,\n\u001b[0;32m   1530\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1531\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1532\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mdecoder_head_mask,\n\u001b[0;32m   1533\u001b[0m     cross_attn_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_head_mask,\n\u001b[0;32m   1534\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1535\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mdecoder_inputs_embeds,\n\u001b[0;32m   1536\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1537\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1538\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1539\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1540\u001b[0m )\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1379\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1367\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1368\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         use_cache,\n\u001b[0;32m   1377\u001b[0m     )\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1379\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m   1380\u001b[0m         hidden_states,\n\u001b[0;32m   1381\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1382\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1383\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[0;32m   1384\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39m(head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1385\u001b[0m         cross_attn_layer_head_mask\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m             cross_attn_head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m cross_attn_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1387\u001b[0m         ),\n\u001b[0;32m   1388\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[0;32m   1389\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1390\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1391\u001b[0m     )\n\u001b[0;32m   1392\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\bart\\modeling_bart.py:703\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    701\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(hidden_states))\n\u001b[0;32m    702\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m--> 703\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    monitor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
